{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "IPython.notebook.set_autosave_interval(300000)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 300 seconds\n"
     ]
    }
   ],
   "source": [
    "%autosave 300\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/batch/tasks/shared/LS_root/mounts/clusters/copilot-model-run/code/Users/Soutrik.Chowdhury/datasource_hackathon\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"..\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.width\", None)\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "from autogluon.timeseries import TimeSeriesDataFrame, TimeSeriesPredictor\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "from autogluon.common import space\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_feats_df = pd.read_pickle(\"engineered_data/merged_data_engineered_all_features_weekly.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1615437, 86)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_feats_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_feats_df = all_feats_df.drop(\n",
    "    columns=[\"Price\", \"Inventory\"], axis=1, errors=\"ignore\"\n",
    ")\n",
    "all_feats_df.replace([np.inf, -np.inf], 1e-6, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_feats_df[\n",
    "    [\n",
    "        \"Client\",\n",
    "        \"Warehouse\",\n",
    "        \"Product\",\n",
    "        \"monthly_inventory_category\",\n",
    "        \"weekly_inventory_category\",\n",
    "        \"monthly_period_inventory_category\",\n",
    "        \"demand_category\",\n",
    "        \"Month\",\n",
    "    ]\n",
    "] = all_feats_df[\n",
    "    [\n",
    "        \"Client\",\n",
    "        \"Warehouse\",\n",
    "        \"Product\",\n",
    "        \"monthly_inventory_category\",\n",
    "        \"weekly_inventory_category\",\n",
    "        \"monthly_period_inventory_category\",\n",
    "        \"demand_category\",\n",
    "        \"Month\",\n",
    "    ]\n",
    "].astype(\n",
    "    \"object\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_dt = all_feats_df.loc[all_feats_df[\"Tag\"] == \"Train\", \"Date\"].max() - pd.DateOffset(\n",
    "#     weeks=3\n",
    "# )\n",
    "# val_dt = str(val_dt.date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all_feats_df = all_feats_df.loc[all_feats_df[\"Tag\"] == \"Train\"].copy()\n",
    "# train_df = train_all_feats_df.loc[train_all_feats_df[\"Date\"] < val_dt].copy()\n",
    "# val_df = train_all_feats_df.loc[train_all_feats_df[\"Date\"] >= val_dt].copy()\n",
    "test_all_feats_df = all_feats_df.loc[all_feats_df[\"Tag\"] == \"Test\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1419748, 84), (195689, 84))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_all_feats_df.shape, test_all_feats_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all_feats_df = train_all_feats_df.set_index([\"id\", \"Date\"])\n",
    "test_all_feats_df = test_all_feats_df.set_index([\"id\", \"Date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_cols = [\n",
    "    \"Sales_roll_mean_6_lag_13\",\n",
    "    \"demand_category\",\n",
    "    \"Sales_roll_median_6_lag_13\",\n",
    "    \"Sales_ewm_alpha_08_lag_13\",\n",
    "    \"Client\",\n",
    "    \"Sales_lag_16\",\n",
    "    \"Warehouse\",\n",
    "    \"Sales_roll_max_6_lag_13\",\n",
    "    \"Sales_ewm_alpha_09_lag_13\",\n",
    "    \"Sales_lag_13\",\n",
    "    \"Sales_roll_mean_5_lag_13\",\n",
    "    \"Sales_ewm_alpha_085_lag_13\",\n",
    "    \"Sales_roll_mean_4_lag_13\",\n",
    "    \"Sales_ewm_alpha_08_lag_14\",\n",
    "    \"Product\",\n",
    "    \"Sales_roll_median_5_lag_13\",\n",
    "    \"weekly_inventory_category\",\n",
    "    \"Sales_roll_min_6_lag_13\",\n",
    "    \"Month\",\n",
    "    \"Price_roll_max_5_lag_13\",\n",
    "    \"Sales_roll_max_5_lag_13\",\n",
    "    \"Sales_roll_max_4_lag_13\",\n",
    "    \"Price_ewm_alpha_08_lag_14\",\n",
    "    \"Price_roll_mean_3_lag_13\",\n",
    "    \"Sales_roll_median_4_lag_13\",\n",
    "    \"Price_roll_max_6_lag_13\",\n",
    "    \"Sales_roll_min_5_lag_13\",\n",
    "    \"Month_cos\",\n",
    "    \"new_combination\",\n",
    "    'Sales'\n",
    "]\n",
    "\n",
    "# keep_cols = train_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 'Sales'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all_feats_df = train_all_feats_df[keep_cols]\n",
    "# y_val = val_df[label]\n",
    "# val_df_nolabel = val_df.drop(columns=[label])\n",
    "test_all_feats_df = test_all_feats_df[[col for col in keep_cols if col != label]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1419748, 30), (195689, 29))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_all_feats_df.shape, test_all_feats_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Sales_roll_mean_6_lag_13</th>\n",
       "      <th>demand_category</th>\n",
       "      <th>Sales_roll_median_6_lag_13</th>\n",
       "      <th>Sales_ewm_alpha_08_lag_13</th>\n",
       "      <th>Client</th>\n",
       "      <th>Sales_lag_16</th>\n",
       "      <th>Warehouse</th>\n",
       "      <th>Sales_roll_max_6_lag_13</th>\n",
       "      <th>Sales_ewm_alpha_09_lag_13</th>\n",
       "      <th>Sales_lag_13</th>\n",
       "      <th>Sales_roll_mean_5_lag_13</th>\n",
       "      <th>Sales_ewm_alpha_085_lag_13</th>\n",
       "      <th>Sales_roll_mean_4_lag_13</th>\n",
       "      <th>Sales_ewm_alpha_08_lag_14</th>\n",
       "      <th>Product</th>\n",
       "      <th>Sales_roll_median_5_lag_13</th>\n",
       "      <th>weekly_inventory_category</th>\n",
       "      <th>Sales_roll_min_6_lag_13</th>\n",
       "      <th>Month</th>\n",
       "      <th>Price_roll_max_5_lag_13</th>\n",
       "      <th>Sales_roll_max_5_lag_13</th>\n",
       "      <th>Sales_roll_max_4_lag_13</th>\n",
       "      <th>Price_ewm_alpha_08_lag_14</th>\n",
       "      <th>Price_roll_mean_3_lag_13</th>\n",
       "      <th>Sales_roll_median_4_lag_13</th>\n",
       "      <th>Price_roll_max_6_lag_13</th>\n",
       "      <th>Sales_roll_min_5_lag_13</th>\n",
       "      <th>Month_cos</th>\n",
       "      <th>new_combination</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0_100_10705</th>\n",
       "      <th>2020-07-06</th>\n",
       "      <td>7.000702</td>\n",
       "      <td>Irregular</td>\n",
       "      <td>7.001213</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.001045</td>\n",
       "      <td>100</td>\n",
       "      <td>6.997820</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.999956</td>\n",
       "      <td>6.999061</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.000282</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10705</td>\n",
       "      <td>6.999089</td>\n",
       "      <td>Low</td>\n",
       "      <td>7.000302</td>\n",
       "      <td>7</td>\n",
       "      <td>17.291164</td>\n",
       "      <td>7.001079</td>\n",
       "      <td>6.998860</td>\n",
       "      <td>17.289999</td>\n",
       "      <td>17.290580</td>\n",
       "      <td>6.999895</td>\n",
       "      <td>17.288134</td>\n",
       "      <td>6.999345</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-13</th>\n",
       "      <td>7.000980</td>\n",
       "      <td>Irregular</td>\n",
       "      <td>6.999069</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.999520</td>\n",
       "      <td>100</td>\n",
       "      <td>6.999653</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.001150</td>\n",
       "      <td>7.001336</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.000889</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10705</td>\n",
       "      <td>6.999107</td>\n",
       "      <td>Low</td>\n",
       "      <td>7.000202</td>\n",
       "      <td>7</td>\n",
       "      <td>17.289666</td>\n",
       "      <td>7.000134</td>\n",
       "      <td>6.999315</td>\n",
       "      <td>17.289999</td>\n",
       "      <td>17.289972</td>\n",
       "      <td>6.999154</td>\n",
       "      <td>17.291274</td>\n",
       "      <td>7.000360</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-20</th>\n",
       "      <td>7.000921</td>\n",
       "      <td>Irregular</td>\n",
       "      <td>6.999116</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.000849</td>\n",
       "      <td>100</td>\n",
       "      <td>6.998909</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.996373</td>\n",
       "      <td>7.000144</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.999724</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10705</td>\n",
       "      <td>7.001587</td>\n",
       "      <td>Low</td>\n",
       "      <td>6.999613</td>\n",
       "      <td>7</td>\n",
       "      <td>17.288844</td>\n",
       "      <td>7.000818</td>\n",
       "      <td>6.999085</td>\n",
       "      <td>17.289999</td>\n",
       "      <td>17.289206</td>\n",
       "      <td>7.002249</td>\n",
       "      <td>17.289541</td>\n",
       "      <td>6.999844</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-27</th>\n",
       "      <td>7.002056</td>\n",
       "      <td>Irregular</td>\n",
       "      <td>7.000202</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.999729</td>\n",
       "      <td>100</td>\n",
       "      <td>6.999676</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.000848</td>\n",
       "      <td>6.997926</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.997879</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10705</td>\n",
       "      <td>7.000940</td>\n",
       "      <td>Low</td>\n",
       "      <td>7.001288</td>\n",
       "      <td>7</td>\n",
       "      <td>17.290436</td>\n",
       "      <td>6.998798</td>\n",
       "      <td>6.999915</td>\n",
       "      <td>17.289999</td>\n",
       "      <td>17.289881</td>\n",
       "      <td>6.999028</td>\n",
       "      <td>17.287816</td>\n",
       "      <td>6.999233</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-03</th>\n",
       "      <td>6.999836</td>\n",
       "      <td>Irregular</td>\n",
       "      <td>6.999082</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.000737</td>\n",
       "      <td>100</td>\n",
       "      <td>7.000530</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.002479</td>\n",
       "      <td>6.999862</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.002133</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10705</td>\n",
       "      <td>7.000210</td>\n",
       "      <td>Low</td>\n",
       "      <td>6.999213</td>\n",
       "      <td>8</td>\n",
       "      <td>17.291488</td>\n",
       "      <td>6.998855</td>\n",
       "      <td>7.000501</td>\n",
       "      <td>17.289999</td>\n",
       "      <td>17.290860</td>\n",
       "      <td>7.000520</td>\n",
       "      <td>17.290718</td>\n",
       "      <td>6.999963</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Sales_roll_mean_6_lag_13 demand_category  \\\n",
       "id          Date                                                   \n",
       "0_100_10705 2020-07-06                  7.000702       Irregular   \n",
       "            2020-07-13                  7.000980       Irregular   \n",
       "            2020-07-20                  7.000921       Irregular   \n",
       "            2020-07-27                  7.002056       Irregular   \n",
       "            2020-08-03                  6.999836       Irregular   \n",
       "\n",
       "                        Sales_roll_median_6_lag_13  Sales_ewm_alpha_08_lag_13  \\\n",
       "id          Date                                                                \n",
       "0_100_10705 2020-07-06                    7.001213                        7.0   \n",
       "            2020-07-13                    6.999069                        7.0   \n",
       "            2020-07-20                    6.999116                        7.0   \n",
       "            2020-07-27                    7.000202                        7.0   \n",
       "            2020-08-03                    6.999082                        7.0   \n",
       "\n",
       "                       Client  Sales_lag_16 Warehouse  \\\n",
       "id          Date                                        \n",
       "0_100_10705 2020-07-06      0      7.001045       100   \n",
       "            2020-07-13      0      6.999520       100   \n",
       "            2020-07-20      0      7.000849       100   \n",
       "            2020-07-27      0      6.999729       100   \n",
       "            2020-08-03      0      7.000737       100   \n",
       "\n",
       "                        Sales_roll_max_6_lag_13  Sales_ewm_alpha_09_lag_13  \\\n",
       "id          Date                                                             \n",
       "0_100_10705 2020-07-06                 6.997820                        7.0   \n",
       "            2020-07-13                 6.999653                        7.0   \n",
       "            2020-07-20                 6.998909                        7.0   \n",
       "            2020-07-27                 6.999676                        7.0   \n",
       "            2020-08-03                 7.000530                        7.0   \n",
       "\n",
       "                        Sales_lag_13  Sales_roll_mean_5_lag_13  \\\n",
       "id          Date                                                 \n",
       "0_100_10705 2020-07-06      6.999956                  6.999061   \n",
       "            2020-07-13      7.001150                  7.001336   \n",
       "            2020-07-20      6.996373                  7.000144   \n",
       "            2020-07-27      7.000848                  6.997926   \n",
       "            2020-08-03      7.002479                  6.999862   \n",
       "\n",
       "                        Sales_ewm_alpha_085_lag_13  Sales_roll_mean_4_lag_13  \\\n",
       "id          Date                                                               \n",
       "0_100_10705 2020-07-06                         7.0                  7.000282   \n",
       "            2020-07-13                         7.0                  7.000889   \n",
       "            2020-07-20                         7.0                  6.999724   \n",
       "            2020-07-27                         7.0                  6.997879   \n",
       "            2020-08-03                         7.0                  7.002133   \n",
       "\n",
       "                        Sales_ewm_alpha_08_lag_14 Product  \\\n",
       "id          Date                                            \n",
       "0_100_10705 2020-07-06                        7.0   10705   \n",
       "            2020-07-13                        7.0   10705   \n",
       "            2020-07-20                        7.0   10705   \n",
       "            2020-07-27                        7.0   10705   \n",
       "            2020-08-03                        7.0   10705   \n",
       "\n",
       "                        Sales_roll_median_5_lag_13 weekly_inventory_category  \\\n",
       "id          Date                                                               \n",
       "0_100_10705 2020-07-06                    6.999089                       Low   \n",
       "            2020-07-13                    6.999107                       Low   \n",
       "            2020-07-20                    7.001587                       Low   \n",
       "            2020-07-27                    7.000940                       Low   \n",
       "            2020-08-03                    7.000210                       Low   \n",
       "\n",
       "                        Sales_roll_min_6_lag_13 Month  \\\n",
       "id          Date                                        \n",
       "0_100_10705 2020-07-06                 7.000302     7   \n",
       "            2020-07-13                 7.000202     7   \n",
       "            2020-07-20                 6.999613     7   \n",
       "            2020-07-27                 7.001288     7   \n",
       "            2020-08-03                 6.999213     8   \n",
       "\n",
       "                        Price_roll_max_5_lag_13  Sales_roll_max_5_lag_13  \\\n",
       "id          Date                                                           \n",
       "0_100_10705 2020-07-06                17.291164                 7.001079   \n",
       "            2020-07-13                17.289666                 7.000134   \n",
       "            2020-07-20                17.288844                 7.000818   \n",
       "            2020-07-27                17.290436                 6.998798   \n",
       "            2020-08-03                17.291488                 6.998855   \n",
       "\n",
       "                        Sales_roll_max_4_lag_13  Price_ewm_alpha_08_lag_14  \\\n",
       "id          Date                                                             \n",
       "0_100_10705 2020-07-06                 6.998860                  17.289999   \n",
       "            2020-07-13                 6.999315                  17.289999   \n",
       "            2020-07-20                 6.999085                  17.289999   \n",
       "            2020-07-27                 6.999915                  17.289999   \n",
       "            2020-08-03                 7.000501                  17.289999   \n",
       "\n",
       "                        Price_roll_mean_3_lag_13  Sales_roll_median_4_lag_13  \\\n",
       "id          Date                                                               \n",
       "0_100_10705 2020-07-06                 17.290580                    6.999895   \n",
       "            2020-07-13                 17.289972                    6.999154   \n",
       "            2020-07-20                 17.289206                    7.002249   \n",
       "            2020-07-27                 17.289881                    6.999028   \n",
       "            2020-08-03                 17.290860                    7.000520   \n",
       "\n",
       "                        Price_roll_max_6_lag_13  Sales_roll_min_5_lag_13  \\\n",
       "id          Date                                                           \n",
       "0_100_10705 2020-07-06                17.288134                 6.999345   \n",
       "            2020-07-13                17.291274                 7.000360   \n",
       "            2020-07-20                17.289541                 6.999844   \n",
       "            2020-07-27                17.287816                 6.999233   \n",
       "            2020-08-03                17.290718                 6.999963   \n",
       "\n",
       "                        Month_cos  new_combination  Sales  \n",
       "id          Date                                           \n",
       "0_100_10705 2020-07-06  -0.866025                0    7.0  \n",
       "            2020-07-13  -0.866025                0    7.0  \n",
       "            2020-07-20  -0.866025                0    7.0  \n",
       "            2020-07-27  -0.866025                0    7.0  \n",
       "            2020-08-03  -0.500000                0    7.0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_all_feats_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_feats_df_train[\"Sales\"] = np.log(all_feats_df_train[\"Sales\"] + 1e-6)\n",
    "# all_feats_df_test[\"Sales\"] = np.log1p(all_feats_df_test[\"Sales\"] + 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric='smape'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_options = (\n",
    "    {  # specifies non-default hyperparameter values for lightGBM gradient boosted trees\n",
    "        \"num_boost_round\": space.Int(lower=100, upper=2000, default=200),\n",
    "        \"num_leaves\": space.Int(lower=10, upper=50, default=36),\n",
    "        \"learning_rate\": space.Real(0.001, 0.1, log=True),\n",
    "    }\n",
    ")\n",
    "xgb_options = (\n",
    "    {  # specifies non-default hyperparameter values for lightGBM gradient boosted trees\n",
    "        \"max_depth\": space.Int(lower=6, upper=30, default=10),\n",
    "        \"eta\": space.Real(0.001, 0.1, log=True),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20240917_133528\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.10.14\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #73~20.04.1-Ubuntu SMP Mon May 6 09:43:44 UTC 2024\n",
      "CPU Count:          16\n",
      "Memory Avail:       97.38 GB / 108.07 GB (90.1%)\n",
      "Disk Space Avail:   5001.87 GB / 5120.00 GB (97.7%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Warning: hyperparameter tuning is currently experimental and may cause the process to hang.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (1419748 samples, 661.86 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20240917_133528\"\n",
      "Train Data Rows:    1419748\n",
      "Train Data Columns: 29\n",
      "Label Column:       Sales\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (13681.0, 0.0, 22.86164, 134.9873)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    100017.81 MB\n",
      "\tTrain Data (Original)  Memory Usage: 614.32 MB (0.6% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 22 | ['Sales_roll_mean_6_lag_13', 'Sales_roll_median_6_lag_13', 'Sales_ewm_alpha_08_lag_13', 'Sales_lag_16', 'Sales_roll_max_6_lag_13', ...]\n",
      "\t\t('int', [])    :  1 | ['new_combination']\n",
      "\t\t('object', []) :  6 | ['demand_category', 'Client', 'Warehouse', 'Product', 'weekly_inventory_category', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  :  6 | ['demand_category', 'Client', 'Warehouse', 'Product', 'weekly_inventory_category', ...]\n",
      "\t\t('float', [])     : 22 | ['Sales_roll_mean_6_lag_13', 'Sales_roll_median_6_lag_13', 'Sales_ewm_alpha_08_lag_13', 'Sales_lag_16', 'Sales_roll_max_6_lag_13', ...]\n",
      "\t\t('int', ['bool']) :  1 | ['new_combination']\n",
      "\t7.1s = Fit runtime\n",
      "\t29 features in original data used to generate 29 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 250.49 MB (0.3% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 7.72s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'symmetric_mean_absolute_percentage_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.02, Train Rows: 1391353, Val Rows: 28395\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'GBM': {'num_boost_round': Int: lower=100, upper=2000, 'num_leaves': Int: lower=10, upper=50, 'learning_rate': Real: lower=0.001, upper=0.1},\n",
      "\t'XGB': {'max_depth': Int: lower=6, upper=30, 'eta': Real: lower=0.001, upper=0.1},\n",
      "}\n",
      "Fitting 2 L1 models ...\n",
      "Hyperparameter tuning model: LightGBM ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b020787e50d441fb6c6b9e0e07c3156",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l2: 3698.87\tvalid_set's symmetric_mean_absolute_percentage_error: -0.702136\n",
      "[1000]\tvalid_set's l2: 4193.41\tvalid_set's symmetric_mean_absolute_percentage_error: -0.715124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitted model: LightGBM/T1 ...\n",
      "\t-0.7733\t = Validation score   (-symmetric_mean_absolute_percentage_error)\n",
      "\t9.0s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitted model: LightGBM/T2 ...\n",
      "\t-0.6459\t = Validation score   (-symmetric_mean_absolute_percentage_error)\n",
      "\t9.16s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitted model: LightGBM/T3 ...\n",
      "\t-0.6425\t = Validation score   (-symmetric_mean_absolute_percentage_error)\n",
      "\t15.48s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitted model: LightGBM/T4 ...\n",
      "\t-0.6405\t = Validation score   (-symmetric_mean_absolute_percentage_error)\n",
      "\t5.13s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitted model: LightGBM/T5 ...\n",
      "\t-0.6428\t = Validation score   (-symmetric_mean_absolute_percentage_error)\n",
      "\t24.47s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitted model: LightGBM/T6 ...\n",
      "\t-0.6986\t = Validation score   (-symmetric_mean_absolute_percentage_error)\n",
      "\t26.27s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitted model: LightGBM/T7 ...\n",
      "\t-0.643\t = Validation score   (-symmetric_mean_absolute_percentage_error)\n",
      "\t5.83s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitted model: LightGBM/T8 ...\n",
      "\t-0.6417\t = Validation score   (-symmetric_mean_absolute_percentage_error)\n",
      "\t20.95s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitted model: LightGBM/T9 ...\n",
      "\t-0.7108\t = Validation score   (-symmetric_mean_absolute_percentage_error)\n",
      "\t21.0s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitted model: LightGBM/T10 ...\n",
      "\t-0.6532\t = Validation score   (-symmetric_mean_absolute_percentage_error)\n",
      "\t31.7s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitted model: LightGBM/T11 ...\n",
      "\t-0.684\t = Validation score   (-symmetric_mean_absolute_percentage_error)\n",
      "\t64.78s\t = Training   runtime\n",
      "\t0.32s\t = Validation runtime\n",
      "Fitted model: LightGBM/T12 ...\n",
      "\t-0.6419\t = Validation score   (-symmetric_mean_absolute_percentage_error)\n",
      "\t5.42s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitted model: LightGBM/T13 ...\n",
      "\t-0.6455\t = Validation score   (-symmetric_mean_absolute_percentage_error)\n",
      "\t7.47s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitted model: LightGBM/T14 ...\n",
      "\t-0.7566\t = Validation score   (-symmetric_mean_absolute_percentage_error)\n",
      "\t6.3s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitted model: LightGBM/T15 ...\n",
      "\t-0.7212\t = Validation score   (-symmetric_mean_absolute_percentage_error)\n",
      "\t7.47s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Hyperparameter tuning model: XGBoost ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa2ee1e005c24fb387c5f01fcf1a0593",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tWarning: Not enough memory to safely train model. Estimated to require 95659.419 GB out of 103.219 GB available memory (92676.505%)... (100.000% of avail memory is the max safe size)\n",
      "\tTo force training the model, specify the model hyperparameter \"ag.max_memory_usage_ratio\" to a larger value (currently 1.0, set to >=926.82 to avoid the error)\n",
      "\t\tTo set the same value for all models, do the following when calling predictor.fit: `predictor.fit(..., ag_args_fit={\"ag.max_memory_usage_ratio\": VALUE})`\n",
      "\t\tSetting \"ag.max_memory_usage_ratio\" to values above 1 may result in out-of-memory errors. You may consider using a machine with more memory as a safer alternative.\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/torch_env/lib/python3.10/site-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
      "    model = fit_and_save_model(\n",
      "  File \"/anaconda/envs/torch_env/lib/python3.10/site-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
      "    model.fit(**fit_args, time_limit=time_left)\n",
      "  File \"/anaconda/envs/torch_env/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 855, in fit\n",
      "    self._validate_fit_memory_usage(**kwargs)\n",
      "  File \"/anaconda/envs/torch_env/lib/python3.10/site-packages/autogluon/tabular/models/xgboost/xgboost_model.py\", line 230, in _validate_fit_memory_usage\n",
      "    return super()._validate_fit_memory_usage(\n",
      "  File \"/anaconda/envs/torch_env/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1815, in _validate_fit_memory_usage\n",
      "    raise NotEnoughMemoryError\n",
      "autogluon.core.utils.exceptions.NotEnoughMemoryError\n",
      "\tWarning: Potentially not enough memory to safely train model. Estimated to require 95.323 GB out of 103.204 GB available memory (92.364%)... (100.000% of avail memory is the max safe size)\n",
      "\tTo avoid this warning, specify the model hyperparameter \"ag.max_memory_usage_ratio\" to a larger value (currently 1.0, set to >=1.28 to avoid the warning)\n",
      "\t\tTo set the same value for all models, do the following when calling predictor.fit: `predictor.fit(..., ag_args_fit={\"ag.max_memory_usage_ratio\": VALUE})`\n",
      "\t\tSetting \"ag.max_memory_usage_ratio\" to values above 1 may result in out-of-memory errors. You may consider using a machine with more memory as a safer alternative.\n",
      "\tWarning: Not enough memory to safely train model. Estimated to require 5980.502 GB out of 103.109 GB available memory (5800.183%)... (100.000% of avail memory is the max safe size)\n",
      "\tTo force training the model, specify the model hyperparameter \"ag.max_memory_usage_ratio\" to a larger value (currently 1.0, set to >=58.05 to avoid the error)\n",
      "\t\tTo set the same value for all models, do the following when calling predictor.fit: `predictor.fit(..., ag_args_fit={\"ag.max_memory_usage_ratio\": VALUE})`\n",
      "\t\tSetting \"ag.max_memory_usage_ratio\" to values above 1 may result in out-of-memory errors. You may consider using a machine with more memory as a safer alternative.\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/torch_env/lib/python3.10/site-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
      "    model = fit_and_save_model(\n",
      "  File \"/anaconda/envs/torch_env/lib/python3.10/site-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
      "    model.fit(**fit_args, time_limit=time_left)\n",
      "  File \"/anaconda/envs/torch_env/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 855, in fit\n",
      "    self._validate_fit_memory_usage(**kwargs)\n",
      "  File \"/anaconda/envs/torch_env/lib/python3.10/site-packages/autogluon/tabular/models/xgboost/xgboost_model.py\", line 230, in _validate_fit_memory_usage\n",
      "    return super()._validate_fit_memory_usage(\n",
      "  File \"/anaconda/envs/torch_env/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1815, in _validate_fit_memory_usage\n",
      "    raise NotEnoughMemoryError\n",
      "autogluon.core.utils.exceptions.NotEnoughMemoryError\n",
      "\tWarning: Not enough memory to safely train model. Estimated to require 2991.205 GB out of 103.129 GB available memory (2900.443%)... (100.000% of avail memory is the max safe size)\n",
      "\tTo force training the model, specify the model hyperparameter \"ag.max_memory_usage_ratio\" to a larger value (currently 1.0, set to >=29.05 to avoid the error)\n",
      "\t\tTo set the same value for all models, do the following when calling predictor.fit: `predictor.fit(..., ag_args_fit={\"ag.max_memory_usage_ratio\": VALUE})`\n",
      "\t\tSetting \"ag.max_memory_usage_ratio\" to values above 1 may result in out-of-memory errors. You may consider using a machine with more memory as a safer alternative.\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/torch_env/lib/python3.10/site-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
      "    model = fit_and_save_model(\n",
      "  File \"/anaconda/envs/torch_env/lib/python3.10/site-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
      "    model.fit(**fit_args, time_limit=time_left)\n",
      "  File \"/anaconda/envs/torch_env/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 855, in fit\n",
      "    self._validate_fit_memory_usage(**kwargs)\n",
      "  File \"/anaconda/envs/torch_env/lib/python3.10/site-packages/autogluon/tabular/models/xgboost/xgboost_model.py\", line 230, in _validate_fit_memory_usage\n",
      "    return super()._validate_fit_memory_usage(\n",
      "  File \"/anaconda/envs/torch_env/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1815, in _validate_fit_memory_usage\n",
      "    raise NotEnoughMemoryError\n",
      "autogluon.core.utils.exceptions.NotEnoughMemoryError\n",
      "\tWarning: Not enough memory to safely train model. Estimated to require 5980.502 GB out of 103.205 GB available memory (5794.775%)... (100.000% of avail memory is the max safe size)\n",
      "\tTo force training the model, specify the model hyperparameter \"ag.max_memory_usage_ratio\" to a larger value (currently 1.0, set to >=58.00 to avoid the error)\n",
      "\t\tTo set the same value for all models, do the following when calling predictor.fit: `predictor.fit(..., ag_args_fit={\"ag.max_memory_usage_ratio\": VALUE})`\n",
      "\t\tSetting \"ag.max_memory_usage_ratio\" to values above 1 may result in out-of-memory errors. You may consider using a machine with more memory as a safer alternative.\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/torch_env/lib/python3.10/site-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
      "    model = fit_and_save_model(\n",
      "  File \"/anaconda/envs/torch_env/lib/python3.10/site-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
      "    model.fit(**fit_args, time_limit=time_left)\n",
      "  File \"/anaconda/envs/torch_env/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 855, in fit\n",
      "    self._validate_fit_memory_usage(**kwargs)\n",
      "  File \"/anaconda/envs/torch_env/lib/python3.10/site-packages/autogluon/tabular/models/xgboost/xgboost_model.py\", line 230, in _validate_fit_memory_usage\n",
      "    return super()._validate_fit_memory_usage(\n",
      "  File \"/anaconda/envs/torch_env/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1815, in _validate_fit_memory_usage\n",
      "    raise NotEnoughMemoryError\n",
      "autogluon.core.utils.exceptions.NotEnoughMemoryError\n",
      "\tWarning: Not enough memory to safely train model. Estimated to require 95659.419 GB out of 103.194 GB available memory (92698.344%)... (100.000% of avail memory is the max safe size)\n",
      "\tTo force training the model, specify the model hyperparameter \"ag.max_memory_usage_ratio\" to a larger value (currently 1.0, set to >=927.03 to avoid the error)\n",
      "\t\tTo set the same value for all models, do the following when calling predictor.fit: `predictor.fit(..., ag_args_fit={\"ag.max_memory_usage_ratio\": VALUE})`\n",
      "\t\tSetting \"ag.max_memory_usage_ratio\" to values above 1 may result in out-of-memory errors. You may consider using a machine with more memory as a safer alternative.\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/torch_env/lib/python3.10/site-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
      "    model = fit_and_save_model(\n",
      "  File \"/anaconda/envs/torch_env/lib/python3.10/site-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
      "    model.fit(**fit_args, time_limit=time_left)\n",
      "  File \"/anaconda/envs/torch_env/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 855, in fit\n",
      "    self._validate_fit_memory_usage(**kwargs)\n",
      "  File \"/anaconda/envs/torch_env/lib/python3.10/site-packages/autogluon/tabular/models/xgboost/xgboost_model.py\", line 230, in _validate_fit_memory_usage\n",
      "    return super()._validate_fit_memory_usage(\n",
      "  File \"/anaconda/envs/torch_env/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1815, in _validate_fit_memory_usage\n",
      "    raise NotEnoughMemoryError\n",
      "autogluon.core.utils.exceptions.NotEnoughMemoryError\n",
      "\tWarning: Not enough memory to safely train model. Estimated to require 47830.663 GB out of 103.202 GB available memory (46346.726%)... (100.000% of avail memory is the max safe size)\n",
      "\tTo force training the model, specify the model hyperparameter \"ag.max_memory_usage_ratio\" to a larger value (currently 1.0, set to >=463.52 to avoid the error)\n",
      "\t\tTo set the same value for all models, do the following when calling predictor.fit: `predictor.fit(..., ag_args_fit={\"ag.max_memory_usage_ratio\": VALUE})`\n",
      "\t\tSetting \"ag.max_memory_usage_ratio\" to values above 1 may result in out-of-memory errors. You may consider using a machine with more memory as a safer alternative.\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/torch_env/lib/python3.10/site-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
      "    model = fit_and_save_model(\n",
      "  File \"/anaconda/envs/torch_env/lib/python3.10/site-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
      "    model.fit(**fit_args, time_limit=time_left)\n",
      "  File \"/anaconda/envs/torch_env/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 855, in fit\n",
      "    self._validate_fit_memory_usage(**kwargs)\n",
      "  File \"/anaconda/envs/torch_env/lib/python3.10/site-packages/autogluon/tabular/models/xgboost/xgboost_model.py\", line 230, in _validate_fit_memory_usage\n",
      "    return super()._validate_fit_memory_usage(\n",
      "  File \"/anaconda/envs/torch_env/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1815, in _validate_fit_memory_usage\n",
      "    raise NotEnoughMemoryError\n",
      "autogluon.core.utils.exceptions.NotEnoughMemoryError\n",
      "\tWarning: Not enough memory to safely train model. Estimated to require 11959.096 GB out of 103.194 GB available memory (11588.907%)... (100.000% of avail memory is the max safe size)\n",
      "\tTo force training the model, specify the model hyperparameter \"ag.max_memory_usage_ratio\" to a larger value (currently 1.0, set to >=115.94 to avoid the error)\n",
      "\t\tTo set the same value for all models, do the following when calling predictor.fit: `predictor.fit(..., ag_args_fit={\"ag.max_memory_usage_ratio\": VALUE})`\n",
      "\t\tSetting \"ag.max_memory_usage_ratio\" to values above 1 may result in out-of-memory errors. You may consider using a machine with more memory as a safer alternative.\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/torch_env/lib/python3.10/site-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
      "    model = fit_and_save_model(\n",
      "  File \"/anaconda/envs/torch_env/lib/python3.10/site-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
      "    model.fit(**fit_args, time_limit=time_left)\n",
      "  File \"/anaconda/envs/torch_env/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 855, in fit\n",
      "    self._validate_fit_memory_usage(**kwargs)\n",
      "  File \"/anaconda/envs/torch_env/lib/python3.10/site-packages/autogluon/tabular/models/xgboost/xgboost_model.py\", line 230, in _validate_fit_memory_usage\n",
      "    return super()._validate_fit_memory_usage(\n",
      "  File \"/anaconda/envs/torch_env/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1815, in _validate_fit_memory_usage\n",
      "    raise NotEnoughMemoryError\n",
      "autogluon.core.utils.exceptions.NotEnoughMemoryError\n",
      "\tWarning: Not enough memory to safely train model. Estimated to require 188.738 GB out of 103.170 GB available memory (182.940%)... (100.000% of avail memory is the max safe size)\n",
      "\tTo force training the model, specify the model hyperparameter \"ag.max_memory_usage_ratio\" to a larger value (currently 1.0, set to >=1.88 to avoid the error)\n",
      "\t\tTo set the same value for all models, do the following when calling predictor.fit: `predictor.fit(..., ag_args_fit={\"ag.max_memory_usage_ratio\": VALUE})`\n",
      "\t\tSetting \"ag.max_memory_usage_ratio\" to values above 1 may result in out-of-memory errors. You may consider using a machine with more memory as a safer alternative.\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/torch_env/lib/python3.10/site-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
      "    model = fit_and_save_model(\n",
      "  File \"/anaconda/envs/torch_env/lib/python3.10/site-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
      "    model.fit(**fit_args, time_limit=time_left)\n",
      "  File \"/anaconda/envs/torch_env/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 855, in fit\n",
      "    self._validate_fit_memory_usage(**kwargs)\n",
      "  File \"/anaconda/envs/torch_env/lib/python3.10/site-packages/autogluon/tabular/models/xgboost/xgboost_model.py\", line 230, in _validate_fit_memory_usage\n",
      "    return super()._validate_fit_memory_usage(\n",
      "  File \"/anaconda/envs/torch_env/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1815, in _validate_fit_memory_usage\n",
      "    raise NotEnoughMemoryError\n",
      "autogluon.core.utils.exceptions.NotEnoughMemoryError\n",
      "Fitted model: XGBoost/T1 ...\n",
      "\t-0.6455\t = Validation score   (-symmetric_mean_absolute_percentage_error)\n",
      "\t15.75s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitted model: XGBoost/T2 ...\n",
      "\t-0.6472\t = Validation score   (-symmetric_mean_absolute_percentage_error)\n",
      "\t20.37s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitted model: XGBoost/T4 ...\n",
      "\t-0.6298\t = Validation score   (-symmetric_mean_absolute_percentage_error)\n",
      "\t30.34s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitted model: XGBoost/T6 ...\n",
      "\t-0.654\t = Validation score   (-symmetric_mean_absolute_percentage_error)\n",
      "\t62.89s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitted model: XGBoost/T8 ...\n",
      "\t-0.635\t = Validation score   (-symmetric_mean_absolute_percentage_error)\n",
      "\t19.45s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitted model: XGBoost/T9 ...\n",
      "\t-0.6499\t = Validation score   (-symmetric_mean_absolute_percentage_error)\n",
      "\t16.32s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitted model: XGBoost/T14 ...\n",
      "\t-0.6456\t = Validation score   (-symmetric_mean_absolute_percentage_error)\n",
      "\t12.71s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'XGBoost/T4': 1.0}\n",
      "\t-0.6298\t = Validation score   (-symmetric_mean_absolute_percentage_error)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 572.01s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 355154.8 rows/s (28395 batch size)\n",
      "Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
      "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM/T1_FULL ...\n",
      "\t8.53s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM/T2_FULL ...\n",
      "\t7.63s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM/T3_FULL ...\n",
      "\t10.79s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM/T4_FULL ...\n",
      "\t4.21s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM/T5_FULL ...\n",
      "\t19.45s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM/T6_FULL ...\n",
      "\t28.69s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM/T7_FULL ...\n",
      "\t5.3s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM/T8_FULL ...\n",
      "\t16.41s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM/T9_FULL ...\n",
      "\t20.91s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM/T10_FULL ...\n",
      "\t35.38s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM/T11_FULL ...\n",
      "\t73.35s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM/T12_FULL ...\n",
      "\t4.53s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM/T13_FULL ...\n",
      "\t8.35s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM/T14_FULL ...\n",
      "\t6.46s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM/T15_FULL ...\n",
      "\t7.57s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: XGBoost/T1_FULL ...\n",
      "\t10.51s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: XGBoost/T2_FULL ...\n",
      "\t11.94s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: XGBoost/T4_FULL ...\n",
      "\tWarning: Potentially not enough memory to safely train model. Estimated to require 95.362 GB out of 102.905 GB available memory (92.669%)... (115.000% of avail memory is the max safe size)\n",
      "\tTo avoid this warning, specify the model hyperparameter \"ag.max_memory_usage_ratio\" to a larger value (currently 1.15, set to >=1.29 to avoid the warning)\n",
      "\t\tTo set the same value for all models, do the following when calling predictor.fit: `predictor.fit(..., ag_args_fit={\"ag.max_memory_usage_ratio\": VALUE})`\n",
      "\t\tSetting \"ag.max_memory_usage_ratio\" to values above 1 may result in out-of-memory errors. You may consider using a machine with more memory as a safer alternative.\n",
      "\t20.13s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: XGBoost/T6_FULL ...\n",
      "\t20.64s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: XGBoost/T8_FULL ...\n",
      "\t13.71s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: XGBoost/T9_FULL ...\n",
      "\t10.7s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: XGBoost/T14_FULL ...\n",
      "\t9.52s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\tEnsemble Weights: {'XGBoost/T4': 1.0}\n",
      "\t0.05s\t = Training   runtime\n",
      "Refit complete, total runtime = 371.84s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240917_133528\")\n"
     ]
    }
   ],
   "source": [
    "hyperparameters = {  # hyperparameters of each model type\n",
    "    \"GBM\": gbm_options,\n",
    "    \"XGB\": xgb_options,\n",
    "    #                     \"CAT\":{},\n",
    "}\n",
    "num_trials = (\n",
    "    15  # try at most 5 different hyperparameter configurations for each type of model\n",
    ")\n",
    "search_strategy = (\n",
    "    \"auto\"  # to tune hyperparameters using random search routine with a local scheduler\n",
    ")\n",
    "\n",
    "hyperparameter_tune_kwargs = (\n",
    "    {  # HPO is not performed unless hyperparameter_tune_kwargs is specified\n",
    "        \"num_trials\": num_trials,\n",
    "        \"scheduler\": \"local\",\n",
    "        \"searcher\": search_strategy,\n",
    "    }\n",
    ")  # Refer to TabularPredictor.fit docstring for all valid values\n",
    "\n",
    "predictor = TabularPredictor(label=label, eval_metric=metric).fit(\n",
    "    train_all_feats_df,\n",
    "    hyperparameters=hyperparameters,\n",
    "    hyperparameter_tune_kwargs=hyperparameter_tune_kwargs,\n",
    "    # presets=\"good_quality\",\n",
    "    refit_full=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictor = TabularPredictor.load(\"AutogluonModels/ag-20240917_130706/ds_sub_fit/sub_fit_ho\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost/T4_FULL</td>\n",
       "      <td>-0.619898</td>\n",
       "      <td>NaN</td>\n",
       "      <td>symmetric_mean_absolute_percentage_error</td>\n",
       "      <td>4.616091</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.129684</td>\n",
       "      <td>4.616091</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.129684</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WeightedEnsemble_L2_FULL</td>\n",
       "      <td>-0.619898</td>\n",
       "      <td>NaN</td>\n",
       "      <td>symmetric_mean_absolute_percentage_error</td>\n",
       "      <td>4.751961</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.178502</td>\n",
       "      <td>0.135869</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.048818</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBoost/T4</td>\n",
       "      <td>-0.620201</td>\n",
       "      <td>-0.629758</td>\n",
       "      <td>symmetric_mean_absolute_percentage_error</td>\n",
       "      <td>4.831194</td>\n",
       "      <td>0.079064</td>\n",
       "      <td>30.337206</td>\n",
       "      <td>4.831194</td>\n",
       "      <td>0.079064</td>\n",
       "      <td>30.337206</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>-0.620201</td>\n",
       "      <td>-0.629758</td>\n",
       "      <td>symmetric_mean_absolute_percentage_error</td>\n",
       "      <td>4.957201</td>\n",
       "      <td>0.079951</td>\n",
       "      <td>30.386024</td>\n",
       "      <td>0.126007</td>\n",
       "      <td>0.000887</td>\n",
       "      <td>0.048818</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost/T8</td>\n",
       "      <td>-0.632660</td>\n",
       "      <td>-0.634980</td>\n",
       "      <td>symmetric_mean_absolute_percentage_error</td>\n",
       "      <td>4.402308</td>\n",
       "      <td>0.094063</td>\n",
       "      <td>19.454512</td>\n",
       "      <td>4.402308</td>\n",
       "      <td>0.094063</td>\n",
       "      <td>19.454512</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBoost/T8_FULL</td>\n",
       "      <td>-0.633081</td>\n",
       "      <td>NaN</td>\n",
       "      <td>symmetric_mean_absolute_percentage_error</td>\n",
       "      <td>4.297726</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.711808</td>\n",
       "      <td>4.297726</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.711808</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LightGBM/T4</td>\n",
       "      <td>-0.641257</td>\n",
       "      <td>-0.640522</td>\n",
       "      <td>symmetric_mean_absolute_percentage_error</td>\n",
       "      <td>0.380557</td>\n",
       "      <td>0.011677</td>\n",
       "      <td>5.128417</td>\n",
       "      <td>0.380557</td>\n",
       "      <td>0.011677</td>\n",
       "      <td>5.128417</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LightGBM/T8_FULL</td>\n",
       "      <td>-0.642212</td>\n",
       "      <td>NaN</td>\n",
       "      <td>symmetric_mean_absolute_percentage_error</td>\n",
       "      <td>3.330596</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.413364</td>\n",
       "      <td>3.330596</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.413364</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LightGBM/T8</td>\n",
       "      <td>-0.642342</td>\n",
       "      <td>-0.641700</td>\n",
       "      <td>symmetric_mean_absolute_percentage_error</td>\n",
       "      <td>3.292996</td>\n",
       "      <td>0.066927</td>\n",
       "      <td>20.946405</td>\n",
       "      <td>3.292996</td>\n",
       "      <td>0.066927</td>\n",
       "      <td>20.946405</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LightGBM/T4_FULL</td>\n",
       "      <td>-0.642457</td>\n",
       "      <td>NaN</td>\n",
       "      <td>symmetric_mean_absolute_percentage_error</td>\n",
       "      <td>0.422811</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.213082</td>\n",
       "      <td>0.422811</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.213082</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LightGBM/T12</td>\n",
       "      <td>-0.642685</td>\n",
       "      <td>-0.641932</td>\n",
       "      <td>symmetric_mean_absolute_percentage_error</td>\n",
       "      <td>0.390118</td>\n",
       "      <td>0.011750</td>\n",
       "      <td>5.417105</td>\n",
       "      <td>0.390118</td>\n",
       "      <td>0.011750</td>\n",
       "      <td>5.417105</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LightGBM/T3</td>\n",
       "      <td>-0.643250</td>\n",
       "      <td>-0.642492</td>\n",
       "      <td>symmetric_mean_absolute_percentage_error</td>\n",
       "      <td>1.797487</td>\n",
       "      <td>0.036087</td>\n",
       "      <td>15.477266</td>\n",
       "      <td>1.797487</td>\n",
       "      <td>0.036087</td>\n",
       "      <td>15.477266</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LightGBM/T5</td>\n",
       "      <td>-0.643471</td>\n",
       "      <td>-0.642765</td>\n",
       "      <td>symmetric_mean_absolute_percentage_error</td>\n",
       "      <td>3.796551</td>\n",
       "      <td>0.081903</td>\n",
       "      <td>24.465524</td>\n",
       "      <td>3.796551</td>\n",
       "      <td>0.081903</td>\n",
       "      <td>24.465524</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LightGBM/T7_FULL</td>\n",
       "      <td>-0.643835</td>\n",
       "      <td>NaN</td>\n",
       "      <td>symmetric_mean_absolute_percentage_error</td>\n",
       "      <td>0.519830</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.298002</td>\n",
       "      <td>0.519830</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.298002</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LightGBM/T7</td>\n",
       "      <td>-0.643990</td>\n",
       "      <td>-0.643045</td>\n",
       "      <td>symmetric_mean_absolute_percentage_error</td>\n",
       "      <td>0.529980</td>\n",
       "      <td>0.013915</td>\n",
       "      <td>5.829901</td>\n",
       "      <td>0.529980</td>\n",
       "      <td>0.013915</td>\n",
       "      <td>5.829901</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LightGBM/T12_FULL</td>\n",
       "      <td>-0.644061</td>\n",
       "      <td>NaN</td>\n",
       "      <td>symmetric_mean_absolute_percentage_error</td>\n",
       "      <td>0.409737</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.526783</td>\n",
       "      <td>0.409737</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.526783</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LightGBM/T3_FULL</td>\n",
       "      <td>-0.644379</td>\n",
       "      <td>NaN</td>\n",
       "      <td>symmetric_mean_absolute_percentage_error</td>\n",
       "      <td>1.825867</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.791610</td>\n",
       "      <td>1.825867</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.791610</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LightGBM/T5_FULL</td>\n",
       "      <td>-0.644598</td>\n",
       "      <td>NaN</td>\n",
       "      <td>symmetric_mean_absolute_percentage_error</td>\n",
       "      <td>3.820086</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.448817</td>\n",
       "      <td>3.820086</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.448817</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LightGBM/T13_FULL</td>\n",
       "      <td>-0.645474</td>\n",
       "      <td>NaN</td>\n",
       "      <td>symmetric_mean_absolute_percentage_error</td>\n",
       "      <td>0.997151</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.351594</td>\n",
       "      <td>0.997151</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.351594</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>XGBoost/T1</td>\n",
       "      <td>-0.645632</td>\n",
       "      <td>-0.645462</td>\n",
       "      <td>symmetric_mean_absolute_percentage_error</td>\n",
       "      <td>3.744312</td>\n",
       "      <td>0.068722</td>\n",
       "      <td>15.753053</td>\n",
       "      <td>3.744312</td>\n",
       "      <td>0.068722</td>\n",
       "      <td>15.753053</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>XGBoost/T14_FULL</td>\n",
       "      <td>-0.645733</td>\n",
       "      <td>NaN</td>\n",
       "      <td>symmetric_mean_absolute_percentage_error</td>\n",
       "      <td>3.552546</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.523235</td>\n",
       "      <td>3.552546</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.523235</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>LightGBM/T13</td>\n",
       "      <td>-0.645869</td>\n",
       "      <td>-0.645519</td>\n",
       "      <td>symmetric_mean_absolute_percentage_error</td>\n",
       "      <td>1.051548</td>\n",
       "      <td>0.048329</td>\n",
       "      <td>7.468059</td>\n",
       "      <td>1.051548</td>\n",
       "      <td>0.048329</td>\n",
       "      <td>7.468059</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>XGBoost/T14</td>\n",
       "      <td>-0.645916</td>\n",
       "      <td>-0.645555</td>\n",
       "      <td>symmetric_mean_absolute_percentage_error</td>\n",
       "      <td>3.530997</td>\n",
       "      <td>0.067310</td>\n",
       "      <td>12.710942</td>\n",
       "      <td>3.530997</td>\n",
       "      <td>0.067310</td>\n",
       "      <td>12.710942</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>XGBoost/T1_FULL</td>\n",
       "      <td>-0.646066</td>\n",
       "      <td>NaN</td>\n",
       "      <td>symmetric_mean_absolute_percentage_error</td>\n",
       "      <td>3.971455</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.505097</td>\n",
       "      <td>3.971455</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.505097</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>LightGBM/T2_FULL</td>\n",
       "      <td>-0.646823</td>\n",
       "      <td>NaN</td>\n",
       "      <td>symmetric_mean_absolute_percentage_error</td>\n",
       "      <td>0.985126</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.630097</td>\n",
       "      <td>0.985126</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.630097</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>LightGBM/T2</td>\n",
       "      <td>-0.647027</td>\n",
       "      <td>-0.645940</td>\n",
       "      <td>symmetric_mean_absolute_percentage_error</td>\n",
       "      <td>1.017706</td>\n",
       "      <td>0.042724</td>\n",
       "      <td>9.160938</td>\n",
       "      <td>1.017706</td>\n",
       "      <td>0.042724</td>\n",
       "      <td>9.160938</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>XGBoost/T2</td>\n",
       "      <td>-0.647417</td>\n",
       "      <td>-0.647165</td>\n",
       "      <td>symmetric_mean_absolute_percentage_error</td>\n",
       "      <td>3.989465</td>\n",
       "      <td>0.080861</td>\n",
       "      <td>20.372811</td>\n",
       "      <td>3.989465</td>\n",
       "      <td>0.080861</td>\n",
       "      <td>20.372811</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>XGBoost/T2_FULL</td>\n",
       "      <td>-0.647577</td>\n",
       "      <td>NaN</td>\n",
       "      <td>symmetric_mean_absolute_percentage_error</td>\n",
       "      <td>4.026082</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.935568</td>\n",
       "      <td>4.026082</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.935568</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>XGBoost/T9_FULL</td>\n",
       "      <td>-0.649765</td>\n",
       "      <td>NaN</td>\n",
       "      <td>symmetric_mean_absolute_percentage_error</td>\n",
       "      <td>3.780371</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.698512</td>\n",
       "      <td>3.780371</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.698512</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>XGBoost/T9</td>\n",
       "      <td>-0.650286</td>\n",
       "      <td>-0.649852</td>\n",
       "      <td>symmetric_mean_absolute_percentage_error</td>\n",
       "      <td>3.707675</td>\n",
       "      <td>0.068404</td>\n",
       "      <td>16.317112</td>\n",
       "      <td>3.707675</td>\n",
       "      <td>0.068404</td>\n",
       "      <td>16.317112</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>LightGBM/T10</td>\n",
       "      <td>-0.653576</td>\n",
       "      <td>-0.653164</td>\n",
       "      <td>symmetric_mean_absolute_percentage_error</td>\n",
       "      <td>7.401746</td>\n",
       "      <td>0.141813</td>\n",
       "      <td>31.702762</td>\n",
       "      <td>7.401746</td>\n",
       "      <td>0.141813</td>\n",
       "      <td>31.702762</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>LightGBM/T10_FULL</td>\n",
       "      <td>-0.653907</td>\n",
       "      <td>NaN</td>\n",
       "      <td>symmetric_mean_absolute_percentage_error</td>\n",
       "      <td>7.382473</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.379171</td>\n",
       "      <td>7.382473</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.379171</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>XGBoost/T6</td>\n",
       "      <td>-0.654330</td>\n",
       "      <td>-0.653975</td>\n",
       "      <td>symmetric_mean_absolute_percentage_error</td>\n",
       "      <td>5.839880</td>\n",
       "      <td>0.108250</td>\n",
       "      <td>62.886531</td>\n",
       "      <td>5.839880</td>\n",
       "      <td>0.108250</td>\n",
       "      <td>62.886531</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>XGBoost/T6_FULL</td>\n",
       "      <td>-0.654331</td>\n",
       "      <td>NaN</td>\n",
       "      <td>symmetric_mean_absolute_percentage_error</td>\n",
       "      <td>5.545744</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.644387</td>\n",
       "      <td>5.545744</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.644387</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>LightGBM/T11_FULL</td>\n",
       "      <td>-0.683495</td>\n",
       "      <td>NaN</td>\n",
       "      <td>symmetric_mean_absolute_percentage_error</td>\n",
       "      <td>14.289085</td>\n",
       "      <td>NaN</td>\n",
       "      <td>73.348126</td>\n",
       "      <td>14.289085</td>\n",
       "      <td>NaN</td>\n",
       "      <td>73.348126</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>LightGBM/T11</td>\n",
       "      <td>-0.683739</td>\n",
       "      <td>-0.684027</td>\n",
       "      <td>symmetric_mean_absolute_percentage_error</td>\n",
       "      <td>14.404230</td>\n",
       "      <td>0.320213</td>\n",
       "      <td>64.784215</td>\n",
       "      <td>14.404230</td>\n",
       "      <td>0.320213</td>\n",
       "      <td>64.784215</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>LightGBM/T6_FULL</td>\n",
       "      <td>-0.698216</td>\n",
       "      <td>NaN</td>\n",
       "      <td>symmetric_mean_absolute_percentage_error</td>\n",
       "      <td>4.878035</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.694288</td>\n",
       "      <td>4.878035</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.694288</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>LightGBM/T6</td>\n",
       "      <td>-0.698314</td>\n",
       "      <td>-0.698641</td>\n",
       "      <td>symmetric_mean_absolute_percentage_error</td>\n",
       "      <td>4.872366</td>\n",
       "      <td>0.093280</td>\n",
       "      <td>26.265916</td>\n",
       "      <td>4.872366</td>\n",
       "      <td>0.093280</td>\n",
       "      <td>26.265916</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>LightGBM/T9_FULL</td>\n",
       "      <td>-0.710162</td>\n",
       "      <td>NaN</td>\n",
       "      <td>symmetric_mean_absolute_percentage_error</td>\n",
       "      <td>3.324087</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.911382</td>\n",
       "      <td>3.324087</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.911382</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>LightGBM/T9</td>\n",
       "      <td>-0.710306</td>\n",
       "      <td>-0.710790</td>\n",
       "      <td>symmetric_mean_absolute_percentage_error</td>\n",
       "      <td>3.222161</td>\n",
       "      <td>0.063212</td>\n",
       "      <td>20.998959</td>\n",
       "      <td>3.222161</td>\n",
       "      <td>0.063212</td>\n",
       "      <td>20.998959</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>LightGBM/T15_FULL</td>\n",
       "      <td>-0.720500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>symmetric_mean_absolute_percentage_error</td>\n",
       "      <td>0.802656</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.572736</td>\n",
       "      <td>0.802656</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.572736</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>LightGBM/T15</td>\n",
       "      <td>-0.720685</td>\n",
       "      <td>-0.721219</td>\n",
       "      <td>symmetric_mean_absolute_percentage_error</td>\n",
       "      <td>0.792680</td>\n",
       "      <td>0.017325</td>\n",
       "      <td>7.472451</td>\n",
       "      <td>0.792680</td>\n",
       "      <td>0.017325</td>\n",
       "      <td>7.472451</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>LightGBM/T14_FULL</td>\n",
       "      <td>-0.755569</td>\n",
       "      <td>NaN</td>\n",
       "      <td>symmetric_mean_absolute_percentage_error</td>\n",
       "      <td>0.548902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.456004</td>\n",
       "      <td>0.548902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.456004</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>LightGBM/T14</td>\n",
       "      <td>-0.755819</td>\n",
       "      <td>-0.756578</td>\n",
       "      <td>symmetric_mean_absolute_percentage_error</td>\n",
       "      <td>0.599974</td>\n",
       "      <td>0.012976</td>\n",
       "      <td>6.304508</td>\n",
       "      <td>0.599974</td>\n",
       "      <td>0.012976</td>\n",
       "      <td>6.304508</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>LightGBM/T1_FULL</td>\n",
       "      <td>-0.772219</td>\n",
       "      <td>NaN</td>\n",
       "      <td>symmetric_mean_absolute_percentage_error</td>\n",
       "      <td>0.976604</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.525033</td>\n",
       "      <td>0.976604</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.525033</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>LightGBM/T1</td>\n",
       "      <td>-0.772248</td>\n",
       "      <td>-0.773334</td>\n",
       "      <td>symmetric_mean_absolute_percentage_error</td>\n",
       "      <td>1.030327</td>\n",
       "      <td>0.021591</td>\n",
       "      <td>9.003628</td>\n",
       "      <td>1.030327</td>\n",
       "      <td>0.021591</td>\n",
       "      <td>9.003628</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       model  score_test  score_val  \\\n",
       "0            XGBoost/T4_FULL   -0.619898        NaN   \n",
       "1   WeightedEnsemble_L2_FULL   -0.619898        NaN   \n",
       "2                 XGBoost/T4   -0.620201  -0.629758   \n",
       "3        WeightedEnsemble_L2   -0.620201  -0.629758   \n",
       "4                 XGBoost/T8   -0.632660  -0.634980   \n",
       "5            XGBoost/T8_FULL   -0.633081        NaN   \n",
       "6                LightGBM/T4   -0.641257  -0.640522   \n",
       "7           LightGBM/T8_FULL   -0.642212        NaN   \n",
       "8                LightGBM/T8   -0.642342  -0.641700   \n",
       "9           LightGBM/T4_FULL   -0.642457        NaN   \n",
       "10              LightGBM/T12   -0.642685  -0.641932   \n",
       "11               LightGBM/T3   -0.643250  -0.642492   \n",
       "12               LightGBM/T5   -0.643471  -0.642765   \n",
       "13          LightGBM/T7_FULL   -0.643835        NaN   \n",
       "14               LightGBM/T7   -0.643990  -0.643045   \n",
       "15         LightGBM/T12_FULL   -0.644061        NaN   \n",
       "16          LightGBM/T3_FULL   -0.644379        NaN   \n",
       "17          LightGBM/T5_FULL   -0.644598        NaN   \n",
       "18         LightGBM/T13_FULL   -0.645474        NaN   \n",
       "19                XGBoost/T1   -0.645632  -0.645462   \n",
       "20          XGBoost/T14_FULL   -0.645733        NaN   \n",
       "21              LightGBM/T13   -0.645869  -0.645519   \n",
       "22               XGBoost/T14   -0.645916  -0.645555   \n",
       "23           XGBoost/T1_FULL   -0.646066        NaN   \n",
       "24          LightGBM/T2_FULL   -0.646823        NaN   \n",
       "25               LightGBM/T2   -0.647027  -0.645940   \n",
       "26                XGBoost/T2   -0.647417  -0.647165   \n",
       "27           XGBoost/T2_FULL   -0.647577        NaN   \n",
       "28           XGBoost/T9_FULL   -0.649765        NaN   \n",
       "29                XGBoost/T9   -0.650286  -0.649852   \n",
       "30              LightGBM/T10   -0.653576  -0.653164   \n",
       "31         LightGBM/T10_FULL   -0.653907        NaN   \n",
       "32                XGBoost/T6   -0.654330  -0.653975   \n",
       "33           XGBoost/T6_FULL   -0.654331        NaN   \n",
       "34         LightGBM/T11_FULL   -0.683495        NaN   \n",
       "35              LightGBM/T11   -0.683739  -0.684027   \n",
       "36          LightGBM/T6_FULL   -0.698216        NaN   \n",
       "37               LightGBM/T6   -0.698314  -0.698641   \n",
       "38          LightGBM/T9_FULL   -0.710162        NaN   \n",
       "39               LightGBM/T9   -0.710306  -0.710790   \n",
       "40         LightGBM/T15_FULL   -0.720500        NaN   \n",
       "41              LightGBM/T15   -0.720685  -0.721219   \n",
       "42         LightGBM/T14_FULL   -0.755569        NaN   \n",
       "43              LightGBM/T14   -0.755819  -0.756578   \n",
       "44          LightGBM/T1_FULL   -0.772219        NaN   \n",
       "45               LightGBM/T1   -0.772248  -0.773334   \n",
       "\n",
       "                                 eval_metric  pred_time_test  pred_time_val  \\\n",
       "0   symmetric_mean_absolute_percentage_error        4.616091            NaN   \n",
       "1   symmetric_mean_absolute_percentage_error        4.751961            NaN   \n",
       "2   symmetric_mean_absolute_percentage_error        4.831194       0.079064   \n",
       "3   symmetric_mean_absolute_percentage_error        4.957201       0.079951   \n",
       "4   symmetric_mean_absolute_percentage_error        4.402308       0.094063   \n",
       "5   symmetric_mean_absolute_percentage_error        4.297726            NaN   \n",
       "6   symmetric_mean_absolute_percentage_error        0.380557       0.011677   \n",
       "7   symmetric_mean_absolute_percentage_error        3.330596            NaN   \n",
       "8   symmetric_mean_absolute_percentage_error        3.292996       0.066927   \n",
       "9   symmetric_mean_absolute_percentage_error        0.422811            NaN   \n",
       "10  symmetric_mean_absolute_percentage_error        0.390118       0.011750   \n",
       "11  symmetric_mean_absolute_percentage_error        1.797487       0.036087   \n",
       "12  symmetric_mean_absolute_percentage_error        3.796551       0.081903   \n",
       "13  symmetric_mean_absolute_percentage_error        0.519830            NaN   \n",
       "14  symmetric_mean_absolute_percentage_error        0.529980       0.013915   \n",
       "15  symmetric_mean_absolute_percentage_error        0.409737            NaN   \n",
       "16  symmetric_mean_absolute_percentage_error        1.825867            NaN   \n",
       "17  symmetric_mean_absolute_percentage_error        3.820086            NaN   \n",
       "18  symmetric_mean_absolute_percentage_error        0.997151            NaN   \n",
       "19  symmetric_mean_absolute_percentage_error        3.744312       0.068722   \n",
       "20  symmetric_mean_absolute_percentage_error        3.552546            NaN   \n",
       "21  symmetric_mean_absolute_percentage_error        1.051548       0.048329   \n",
       "22  symmetric_mean_absolute_percentage_error        3.530997       0.067310   \n",
       "23  symmetric_mean_absolute_percentage_error        3.971455            NaN   \n",
       "24  symmetric_mean_absolute_percentage_error        0.985126            NaN   \n",
       "25  symmetric_mean_absolute_percentage_error        1.017706       0.042724   \n",
       "26  symmetric_mean_absolute_percentage_error        3.989465       0.080861   \n",
       "27  symmetric_mean_absolute_percentage_error        4.026082            NaN   \n",
       "28  symmetric_mean_absolute_percentage_error        3.780371            NaN   \n",
       "29  symmetric_mean_absolute_percentage_error        3.707675       0.068404   \n",
       "30  symmetric_mean_absolute_percentage_error        7.401746       0.141813   \n",
       "31  symmetric_mean_absolute_percentage_error        7.382473            NaN   \n",
       "32  symmetric_mean_absolute_percentage_error        5.839880       0.108250   \n",
       "33  symmetric_mean_absolute_percentage_error        5.545744            NaN   \n",
       "34  symmetric_mean_absolute_percentage_error       14.289085            NaN   \n",
       "35  symmetric_mean_absolute_percentage_error       14.404230       0.320213   \n",
       "36  symmetric_mean_absolute_percentage_error        4.878035            NaN   \n",
       "37  symmetric_mean_absolute_percentage_error        4.872366       0.093280   \n",
       "38  symmetric_mean_absolute_percentage_error        3.324087            NaN   \n",
       "39  symmetric_mean_absolute_percentage_error        3.222161       0.063212   \n",
       "40  symmetric_mean_absolute_percentage_error        0.802656            NaN   \n",
       "41  symmetric_mean_absolute_percentage_error        0.792680       0.017325   \n",
       "42  symmetric_mean_absolute_percentage_error        0.548902            NaN   \n",
       "43  symmetric_mean_absolute_percentage_error        0.599974       0.012976   \n",
       "44  symmetric_mean_absolute_percentage_error        0.976604            NaN   \n",
       "45  symmetric_mean_absolute_percentage_error        1.030327       0.021591   \n",
       "\n",
       "     fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n",
       "0   20.129684                 4.616091                     NaN   \n",
       "1   20.178502                 0.135869                     NaN   \n",
       "2   30.337206                 4.831194                0.079064   \n",
       "3   30.386024                 0.126007                0.000887   \n",
       "4   19.454512                 4.402308                0.094063   \n",
       "5   13.711808                 4.297726                     NaN   \n",
       "6    5.128417                 0.380557                0.011677   \n",
       "7   16.413364                 3.330596                     NaN   \n",
       "8   20.946405                 3.292996                0.066927   \n",
       "9    4.213082                 0.422811                     NaN   \n",
       "10   5.417105                 0.390118                0.011750   \n",
       "11  15.477266                 1.797487                0.036087   \n",
       "12  24.465524                 3.796551                0.081903   \n",
       "13   5.298002                 0.519830                     NaN   \n",
       "14   5.829901                 0.529980                0.013915   \n",
       "15   4.526783                 0.409737                     NaN   \n",
       "16  10.791610                 1.825867                     NaN   \n",
       "17  19.448817                 3.820086                     NaN   \n",
       "18   8.351594                 0.997151                     NaN   \n",
       "19  15.753053                 3.744312                0.068722   \n",
       "20   9.523235                 3.552546                     NaN   \n",
       "21   7.468059                 1.051548                0.048329   \n",
       "22  12.710942                 3.530997                0.067310   \n",
       "23  10.505097                 3.971455                     NaN   \n",
       "24   7.630097                 0.985126                     NaN   \n",
       "25   9.160938                 1.017706                0.042724   \n",
       "26  20.372811                 3.989465                0.080861   \n",
       "27  11.935568                 4.026082                     NaN   \n",
       "28  10.698512                 3.780371                     NaN   \n",
       "29  16.317112                 3.707675                0.068404   \n",
       "30  31.702762                 7.401746                0.141813   \n",
       "31  35.379171                 7.382473                     NaN   \n",
       "32  62.886531                 5.839880                0.108250   \n",
       "33  20.644387                 5.545744                     NaN   \n",
       "34  73.348126                14.289085                     NaN   \n",
       "35  64.784215                14.404230                0.320213   \n",
       "36  28.694288                 4.878035                     NaN   \n",
       "37  26.265916                 4.872366                0.093280   \n",
       "38  20.911382                 3.324087                     NaN   \n",
       "39  20.998959                 3.222161                0.063212   \n",
       "40   7.572736                 0.802656                     NaN   \n",
       "41   7.472451                 0.792680                0.017325   \n",
       "42   6.456004                 0.548902                     NaN   \n",
       "43   6.304508                 0.599974                0.012976   \n",
       "44   8.525033                 0.976604                     NaN   \n",
       "45   9.003628                 1.030327                0.021591   \n",
       "\n",
       "    fit_time_marginal  stack_level  can_infer  fit_order  \n",
       "0           20.129684            1       True         41  \n",
       "1            0.048818            2       True         46  \n",
       "2           30.337206            1       True         18  \n",
       "3            0.048818            2       True         23  \n",
       "4           19.454512            1       True         20  \n",
       "5           13.711808            1       True         43  \n",
       "6            5.128417            1       True          4  \n",
       "7           16.413364            1       True         31  \n",
       "8           20.946405            1       True          8  \n",
       "9            4.213082            1       True         27  \n",
       "10           5.417105            1       True         12  \n",
       "11          15.477266            1       True          3  \n",
       "12          24.465524            1       True          5  \n",
       "13           5.298002            1       True         30  \n",
       "14           5.829901            1       True          7  \n",
       "15           4.526783            1       True         35  \n",
       "16          10.791610            1       True         26  \n",
       "17          19.448817            1       True         28  \n",
       "18           8.351594            1       True         36  \n",
       "19          15.753053            1       True         16  \n",
       "20           9.523235            1       True         45  \n",
       "21           7.468059            1       True         13  \n",
       "22          12.710942            1       True         22  \n",
       "23          10.505097            1       True         39  \n",
       "24           7.630097            1       True         25  \n",
       "25           9.160938            1       True          2  \n",
       "26          20.372811            1       True         17  \n",
       "27          11.935568            1       True         40  \n",
       "28          10.698512            1       True         44  \n",
       "29          16.317112            1       True         21  \n",
       "30          31.702762            1       True         10  \n",
       "31          35.379171            1       True         33  \n",
       "32          62.886531            1       True         19  \n",
       "33          20.644387            1       True         42  \n",
       "34          73.348126            1       True         34  \n",
       "35          64.784215            1       True         11  \n",
       "36          28.694288            1       True         29  \n",
       "37          26.265916            1       True          6  \n",
       "38          20.911382            1       True         32  \n",
       "39          20.998959            1       True          9  \n",
       "40           7.572736            1       True         38  \n",
       "41           7.472451            1       True         15  \n",
       "42           6.456004            1       True         37  \n",
       "43           6.304508            1       True         14  \n",
       "44           8.525033            1       True         24  \n",
       "45           9.003628            1       True          1  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard(train_all_feats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:   [3.418315887451172, 3.168344736099243, 3.4642767906188965, 3.455923080444336, 3.306429147720337]\n"
     ]
    }
   ],
   "source": [
    "y_pred = predictor.predict(test_all_feats_df)\n",
    "print(\"Predictions:  \", list(y_pred)[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_all_feats_df_op = test_all_feats_df[[\"Client\", \"Warehouse\", \"Product\"]].copy()\n",
    "test_all_feats_df_op[\"Sales\"] = y_pred\n",
    "test_all_feats_df_op = test_all_feats_df_op.reset_index()\n",
    "test_all_feats_df_op['Date'] = test_all_feats_df_op['Date'].dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_all_feats_df_op = test_all_feats_df_op.pivot(\n",
    "    index=[\"Client\", \"Warehouse\", \"Product\"], columns=\"Date\", values=\"Sales\"\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_all_feats_df_op.index.name = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15053, 16)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_all_feats_df_op.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_all_feats_df_op.to_csv(\"outputs/test_best_feats_df_op.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###################################################### END ##############################################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
